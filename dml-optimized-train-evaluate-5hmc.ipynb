{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "! pip install keras-tuner --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-18T18:00:09.180205Z",
     "iopub.status.busy": "2025-05-18T18:00:09.179191Z",
     "iopub.status.idle": "2025-05-18T18:00:09.190230Z",
     "shell.execute_reply": "2025-05-18T18:00:09.189193Z",
     "shell.execute_reply.started": "2025-05-18T18:00:09.180175Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os, math, time, random, datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(__doc__)\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "# from tensorflow.python.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Input, LSTM, Conv1D, MaxPool1D, BatchNormalization, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras_tuner.tuners import RandomSearch, Hyperband\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras import regularizers\n",
    "import keras_tuner as kt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, precision_recall_curve, average_precision_score\n",
    "\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from mlxtend.plotting import plot_decision_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T18:00:10.978550Z",
     "iopub.status.busy": "2025-05-18T18:00:10.977886Z",
     "iopub.status.idle": "2025-05-18T18:00:10.983650Z",
     "shell.execute_reply": "2025-05-18T18:00:10.982694Z",
     "shell.execute_reply.started": "2025-05-18T18:00:10.978525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SelectiveProgbarLogger(tf.keras.callbacks.ProgbarLogger):\n",
    "    def __init__(self, verbose, epoch_interval, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.default_verbose = verbose\n",
    "        self.epoch_interval = epoch_interval\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, *args, **kwargs):\n",
    "        self.verbose = (\n",
    "            0 \n",
    "                if epoch % self.epoch_interval != 0 \n",
    "                else self.default_verbose\n",
    "        )\n",
    "        super().on_epoch_begin(epoch, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T18:00:15.140911Z",
     "iopub.status.busy": "2025-05-18T18:00:15.140329Z",
     "iopub.status.idle": "2025-05-18T18:00:15.155432Z",
     "shell.execute_reply": "2025-05-18T18:00:15.154518Z",
     "shell.execute_reply.started": "2025-05-18T18:00:15.140885Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_performace(test_num, pred_y, labels):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    for index in range(test_num):\n",
    "        if labels[index] == 1:\n",
    "            if labels[index] == pred_y[index]:\n",
    "                tp = tp + 1\n",
    "            else:\n",
    "                fn = fn + 1\n",
    "        else:\n",
    "            if labels[index] == pred_y[index]:\n",
    "                tn = tn + 1\n",
    "            else:\n",
    "                fp = fp + 1\n",
    "\n",
    "    acc = float(tp + tn) / test_num\n",
    "    precision = float(tp) / (tp + fp)\n",
    "    sensitivity = float(tp) / (tp + fn)\n",
    "    specificity = float(tn) / (tn + fp)\n",
    "    MCC = float(tp * tn - fp * fn) / (np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)))\n",
    "    return acc, precision, sensitivity, specificity, MCC\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=False,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    xmin, xmax = plt.xlim()  # return the current xlim\n",
    "    plt.xlim((xmin, xmax))  # set the xlim to xmin, xmax\n",
    "    plt.ylim(xmin, xmax)  # set the xlim to xmin, xmax\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "\n",
    "def plot_performance(train_loss,val_loss,train_acc,val_acc):\n",
    "    # plot train and validation loss across multiple runs\n",
    "    plt.plot(train_loss, color='blue', label='train')\n",
    "    plt.plot(val_loss, color='orange', label='validation')\n",
    "    plt.title('model train vs validation loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(train_acc, color='blue', label='train')\n",
    "    plt.plot(val_acc, color='orange', label='validation')\n",
    "    plt.title('model train vs validation loss')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper right')\n",
    "    plt.show()\n",
    "def transfer_label_from_prob(proba):\n",
    "    label = [1 if val >= 0.5 else 0 for val in proba]\n",
    "    return label\n",
    "def plot_roc_curve(labels, probality, legend_text, auc_tag=True):\n",
    "    # fpr2, tpr2, thresholds = roc_curve(labels, pred_y)\n",
    "    fpr, tpr, thresholds = roc_curve(labels, probality)  # probas_[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    if auc_tag:\n",
    "        rects1 = plt.plot(fpr, tpr, label=legend_text + ' (AUC=%6.3f) ' % roc_auc)\n",
    "    else:\n",
    "        rects1 = plt.plot(fpr, tpr, label=legend_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T18:00:26.904294Z",
     "iopub.status.busy": "2025-05-18T18:00:26.903978Z",
     "iopub.status.idle": "2025-05-18T18:00:26.926966Z",
     "shell.execute_reply": "2025-05-18T18:00:26.925887Z",
     "shell.execute_reply.started": "2025-05-18T18:00:26.904272Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "str1='250629'\n",
    "def evaluate_classifiers(clfList, X_train, y_train, X_test, y_test, fea_dim, training=True, epoc=100, ep_interval=10, cutoff=0.5):\n",
    "    _accs = []\n",
    "    _aucs = []\n",
    "    _names = []\n",
    "    _specs = []\n",
    "    _sens = []\n",
    "    _mccs = []\n",
    "    _f1scores = []\n",
    "    _proba = []\n",
    "    _training_times = []\n",
    "    _histories = []  # List to store training histories\n",
    "\n",
    "    \n",
    "    for clf in clfList:\n",
    "        try:\n",
    "            if(training):\n",
    "                if(clf[0] == 'DNN'):\n",
    "                    print(\"Traning \"+clf[0])\n",
    "                    callbacks = [\n",
    "                                    EarlyStopping(patience=250, monitor='val_accuracy', restore_best_weights=True),\n",
    "                                    ReduceLROnPlateau(factor=0.25, patience=100, min_lr=1e-5),\n",
    "                                    ModelCheckpoint(str1+'_DNN.weights.h5', monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "                                ]\n",
    "                    time_start = time.time()\n",
    "                    history = clf[1].fit(X_train, y_train, #verbose=1, \n",
    "                               shuffle=True, epochs=epoc, \n",
    "                              callbacks=[SelectiveProgbarLogger(verbose = 0, epoch_interval=ep_interval),callbacks],\n",
    "                              batch_size=64,\n",
    "                              validation_split=0.1)\n",
    "                    time_end = time.time()\n",
    "                    _training_times.append(time_end - time_start)\n",
    "                    print(\"Evaluating \"+clf[0])\n",
    "                    proba = clf[1].predict(X_test)\n",
    "                    _proba.append(proba)\n",
    "                    _histories.append(history)  # Store the training history\n",
    "                if(clf[0] == 'GRU'):\n",
    "                    XTrainRNN =np.array(X_train).reshape(-1, 1, fea_dim)\n",
    "                    XTestRNN = np.array(X_test).reshape(-1, 1, fea_dim)\n",
    "                    print(\"Traning \"+clf[0])\n",
    "                    callbacks = [\n",
    "                                    EarlyStopping(patience=250, monitor='val_accuracy', restore_best_weights=True),\n",
    "                                    ReduceLROnPlateau(factor=0.25, patience=100, min_lr=1e-5),\n",
    "                                    ModelCheckpoint(str1+'_GRU.weights.h5', monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "                                ]\n",
    "                    time_start = time.time()\n",
    "                    history = clf[1].fit(XTrainRNN, y_train, #verbose=1, \n",
    "                               shuffle=True, epochs=epoc, \n",
    "                              callbacks=[SelectiveProgbarLogger(verbose = 0, epoch_interval=ep_interval),callbacks],\n",
    "                              batch_size=64,\n",
    "                              validation_split=0.1)\n",
    "                    time_end = time.time()\n",
    "                    _training_times.append(time_end - time_start)\n",
    "                    print(\"Evaluating \"+clf[0])\n",
    "                    proba = clf[1].predict(XTestRNN)\n",
    "                    _proba.append(proba)\n",
    "                    _histories.append(history)  # Store the training history\n",
    "                if(clf[0] == 'LSTM'):\n",
    "                    XTrainRNN =np.array(X_train).reshape(-1, 1, fea_dim)\n",
    "                    XTestRNN = np.array(X_test).reshape(-1, 1, fea_dim)\n",
    "                    print(\"Traning \"+clf[0])\n",
    "                    callbacks = [\n",
    "                                    EarlyStopping(patience=250, monitor='val_accuracy', restore_best_weights=True),\n",
    "                                    ReduceLROnPlateau(factor=0.25, patience=100, min_lr=1e-5),\n",
    "                                    ModelCheckpoint(str1+'_LSTM.weights.h5', monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "                                ]\n",
    "                    time_start = time.time()\n",
    "                    history = clf[1].fit(XTrainRNN, y_train, #verbose=1, \n",
    "                               shuffle=True, epochs=epoc, \n",
    "                              callbacks=[SelectiveProgbarLogger(verbose = 0, epoch_interval=ep_interval),callbacks],\n",
    "                              batch_size=64,\n",
    "                              validation_split=0.1)\n",
    "                    time_end = time.time()\n",
    "                    _training_times.append(time_end - time_start)\n",
    "                    print(\"Evaluating \"+clf[0])\n",
    "                    proba = clf[1].predict(XTestRNN)\n",
    "                    _proba.append(proba)\n",
    "                    _histories.append(history)  # Store the training history\n",
    "                if(clf[0] == 'CNN'):\n",
    "                    XTrainCNN =np.array(X_train).reshape(-1, fea_dim, 1)\n",
    "                    XTestCNN = np.array(X_test).reshape(-1, fea_dim, 1)\n",
    "                    print(\"Traning \"+clf[0])\n",
    "                    callbacks = [\n",
    "                                    EarlyStopping(patience=250, monitor='val_accuracy', restore_best_weights=True),\n",
    "                                    ReduceLROnPlateau(factor=0.25, patience=150, min_lr=1e-5),\n",
    "                                    ModelCheckpoint(str1+'_CNN.weights.h5', monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "                                ]\n",
    "                 \n",
    "                    time_start = time.time()\n",
    "                    history = clf[1].fit(XTrainCNN, y_train, #verbose=1, \n",
    "                               shuffle=True, epochs=epoc, \n",
    "                              callbacks=[SelectiveProgbarLogger(verbose = 0, epoch_interval=ep_interval),callbacks],\n",
    "                              batch_size=64,\n",
    "                              validation_split=0.1)\n",
    "                    time_end = time.time()\n",
    "                    _training_times.append(time_end - time_start)\n",
    "                    print(\"Evaluating \"+clf[0])\n",
    "                    proba = clf[1].predict(XTestCNN)\n",
    "                    _proba.append(proba)\n",
    "                    _histories.append(history)  # Store the training history\n",
    "                \n",
    "            if(clf[0] == 'DNN'):\n",
    "                print(\"Evaluating \"+clf[0])\n",
    "                proba = clf[1].predict(X_test) \n",
    "            if(clf[0] == 'GRU' or clf[0] == 'LSTM'):\n",
    "                print(\"Evaluating \"+clf[0])\n",
    "                proba = clf[1].predict(XTestRNN)\n",
    "            if(clf[0] == 'CNN'):\n",
    "                print(\"Evaluating \"+clf[0])\n",
    "                proba = clf[1].predict(XTestCNN)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"The error is: \",e)\n",
    "            continue\n",
    "\n",
    "        r_pred = [1 if val >= cutoff else 0 for val in proba]\n",
    "        acc, prec, sens, spec, mcc = calculate_performace(len(y_test), r_pred, y_test) \n",
    "        f1score = f1_score(y_true=y_test, y_pred=r_pred)\n",
    "        fpr, tpr, threshold = roc_curve(y_test, proba)\n",
    "        auc_clf = auc(fpr, tpr)\n",
    "        _aucs.append(auc_clf)\n",
    "        _accs.append(acc)\n",
    "        _sens.append(sens)\n",
    "        _specs.append(spec) \n",
    "        _mccs.append(mcc)\n",
    "        _f1scores.append(f1score)\n",
    "        _names.append(clf[0])\n",
    "        # _proba.append(proba)\n",
    "\n",
    "    scoreDataFrame = pd.DataFrame({'Model':_names, 'Accuracy': _accs, 'ROC AUC': _aucs, 'F1 Score':_f1scores,'Sens':_sens, 'Spec':_specs, 'MCC':_mccs, 'Training Time': _training_times,})\n",
    "    history_list = pd.DataFrame({'Model':_names, 'history':_histories})\n",
    "    return scoreDataFrame, _proba, history_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T18:42:16.930851Z",
     "iopub.status.busy": "2025-05-18T18:42:16.930534Z",
     "iopub.status.idle": "2025-05-18T18:42:16.938374Z",
     "shell.execute_reply": "2025-05-18T18:42:16.937482Z",
     "shell.execute_reply.started": "2025-05-18T18:42:16.930830Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_histories(history_list):\n",
    "    \"\"\"\n",
    "    Plots training and validation loss/accuracy for each model.\n",
    "\n",
    "    Args:\n",
    "        scoreDataFrame (pd.DataFrame): DataFrame containing model names and training histories.\n",
    "    \"\"\"\n",
    "\n",
    "    for index, row in history_list.iterrows():\n",
    "        model_name = row['Model']\n",
    "        history = row['history']\n",
    "        # if model_name=='CNN_LSTM':\n",
    "        #     continue\n",
    "\n",
    "        if history is not None:  # Ensure history is not None\n",
    "            plt.figure(figsize=(12, 5))\n",
    "\n",
    "            # Plot training & validation accuracy values\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.plot(history.history['accuracy'])\n",
    "            plt.plot(history.history['val_accuracy'])\n",
    "            plt.title(f'{model_name} Accuracy')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "            # Plot training & validation loss values\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(history.history['loss'])\n",
    "            plt.plot(history.history['val_loss'])\n",
    "            plt.title(f'{model_name} Loss')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(str1+' '+model_name+' ACC_VS_LOSS.png', dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"No training history available for {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T18:22:30.739823Z",
     "iopub.status.busy": "2025-05-18T18:22:30.739072Z",
     "iopub.status.idle": "2025-05-18T18:22:30.744619Z",
     "shell.execute_reply": "2025-05-18T18:22:30.743709Z",
     "shell.execute_reply.started": "2025-05-18T18:22:30.739794Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get splitted data for classical ML models\n",
    "def getSplitDataSet(X, y, ratio=0.2):\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "\n",
    "    #split data into training and test data. \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio, random_state=245)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T18:22:32.296476Z",
     "iopub.status.busy": "2025-05-18T18:22:32.295828Z",
     "iopub.status.idle": "2025-05-18T18:22:32.486715Z",
     "shell.execute_reply": "2025-05-18T18:22:32.485613Z",
     "shell.execute_reply.started": "2025-05-18T18:22:32.296450Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "url_dataset ='PSCV_all.csv'\n",
    "df_main = pd.read_csv(url_dataset, header=None, dtype=float)\n",
    "\n",
    "y = df_main.iloc[:,:1].values \n",
    "X = df_main.iloc[:,1:].values\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "labels = y = encoder.fit_transform(y.ravel())\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test, minmax_scaler = getSplitDataSet(X, y, ratio=0.2)\n",
    "\n",
    "fea_dim = X_train.shape[1]\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T18:23:21.985904Z",
     "iopub.status.busy": "2025-05-18T18:23:21.985069Z",
     "iopub.status.idle": "2025-05-18T18:23:21.990099Z",
     "shell.execute_reply": "2025-05-18T18:23:21.989103Z",
     "shell.execute_reply.started": "2025-05-18T18:23:21.985876Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_bad_features(pValue,thr):\n",
    "    list_bad_feature=[]\n",
    "    for i in range(len(pValue)):\n",
    "        if pValue[i] < thr:\n",
    "            list_bad_feature.append(i)\n",
    "    return list_bad_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T18:31:00.678213Z",
     "iopub.status.busy": "2025-05-18T18:31:00.677508Z",
     "iopub.status.idle": "2025-05-18T18:31:00.697294Z",
     "shell.execute_reply": "2025-05-18T18:31:00.696036Z",
     "shell.execute_reply.started": "2025-05-18T18:31:00.678189Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Feature selection using Chi-Squared test\n",
    "# This is a statistical test to determine if there is a significant association between the features and the\n",
    "f_score1 = chi2(X_train,y_train)\n",
    "pValue1 = pd.Series(f_score1[1])\n",
    "thr = 0.4 # best at thr = 0.4\n",
    "list_bad_feature1 = get_bad_features(pValue1,thr)\n",
    "np.save('list_bad_feature_fvs.npy',list_bad_feature1)\n",
    "X_train1 = np.delete(X_train, list_bad_feature1, axis=1)\n",
    "X_test1 = np.delete(X_test, list_bad_feature1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T18:31:02.714027Z",
     "iopub.status.busy": "2025-05-18T18:31:02.713322Z",
     "iopub.status.idle": "2025-05-18T18:31:02.718920Z",
     "shell.execute_reply": "2025-05-18T18:31:02.717938Z",
     "shell.execute_reply.started": "2025-05-18T18:31:02.713999Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fea_dim1 = X_train1.shape[1]\n",
    "print(X_train1.shape, y_train.shape)\n",
    "print(X_test1.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T18:31:04.526070Z",
     "iopub.status.busy": "2025-05-18T18:31:04.525138Z",
     "iopub.status.idle": "2025-05-18T18:31:04.535193Z",
     "shell.execute_reply": "2025-05-18T18:31:04.534322Z",
     "shell.execute_reply.started": "2025-05-18T18:31:04.526041Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Reshaping for CNN models\n",
    "XTrainCNN =np.array(X_train1).reshape(-1, fea_dim1, 1)\n",
    "XTestCNN = np.array(X_test1).reshape(-1, fea_dim1, 1)\n",
    "# Reshaping for RNN models\n",
    "XTrainRNN =np.array(X_train1).reshape(-1, 1, fea_dim1)\n",
    "XTestRNN = np.array(X_test1).reshape(-1, 1, fea_dim1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T18:31:06.761770Z",
     "iopub.status.busy": "2025-05-18T18:31:06.761165Z",
     "iopub.status.idle": "2025-05-18T18:31:06.770003Z",
     "shell.execute_reply": "2025-05-18T18:31:06.769078Z",
     "shell.execute_reply.started": "2025-05-18T18:31:06.761742Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "input_shape=X_train1.shape[1:]\n",
    "def build_dnn_model(hp):\n",
    "    model = Sequential()\n",
    "    # Hyperparameters to tune\n",
    "    kernel_regularizer = regularizers.l2(hp.Choice('l2_reg', [1e-2, 1e-3, 1e-4]))\n",
    "    # Tune the number of units in the first Dense layer\n",
    "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "    # Tune the dropout rate\n",
    "    hp_dropout = hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.1)\n",
    "    # Tune the learning rate for the optimizer\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    model.add(tf.keras.layers.Input(shape=input_shape))\n",
    "    model.add(Dense(units=hp_units, activation='relu', kernel_regularizer = kernel_regularizer))\n",
    "    model.add(Dropout(rate=hp_dropout))\n",
    "    \n",
    "    hp_units2 = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "    kernel_regularizer2 = regularizers.l2(hp.Choice('l2_reg', [1e-2, 1e-3, 1e-4]))\n",
    "    hp_dropout2 = hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.1)\n",
    "    model.add(Dense(units=hp_units2, activation='relu', kernel_regularizer = kernel_regularizer2))\n",
    "    model.add(Dropout(rate=hp_dropout2))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Optimizer selection\n",
    "    optimizer_choice = hp.Choice('optimizer', ['adam', 'rmsprop', 'sgd'])\n",
    "    learning_rate = hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_choice == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "\n",
    "    # Compile model with tunable loss\n",
    "    loss_choice = hp.Choice('loss', ['binary_crossentropy', 'mse'])\n",
    "    model.compile(optimizer=optimizer, loss=loss_choice, metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    return model\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    build_dnn_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,  # Number of hyperparameter combinations to try\n",
    "    executions_per_trial=1,  # How many models to build and fit for each trial\n",
    "    directory='dlm',\n",
    "    project_name='dnn_tuning',\n",
    "    overwrite=False\n",
    ")\n",
    "tuner.reload()\n",
    "best_hps = tuner.get_best_hyperparameters(1)[0]\n",
    "_dnn = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model function for tuner\n",
    "input_shape=XTrainRNN.shape[1:]\n",
    "def build_gru_model(hp):\n",
    "    model = Sequential()\n",
    "    kernel_regularizer = regularizers.l2(hp.Choice('l2_reg', [1e-2, 1e-3, 1e-4]))\n",
    "    # Tunable GRU units and dropout\n",
    "    model.add(tf.keras.layers.Input(shape=input_shape))\n",
    "    model.add(GRU(units=hp.Int('gru_units', 16, 128, step=16),\n",
    "                  activation='relu',\n",
    "                  recurrent_activation='relu',\n",
    "                  dropout=hp.Float('gru_dropout', 0.1, 0.5, step=0.1),\n",
    "                  kernel_regularizer = kernel_regularizer,\n",
    "                  ))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=hp.Int('dense_units', 32, 512, step=32), activation='relu',kernel_regularizer = kernel_regularizer))\n",
    "    model.add(Dropout(hp.Float('dense_dropout', 0.1, 0.5, step=0.1)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Optimizer and learning rate\n",
    "    optimizer_choice = hp.Choice('optimizer', ['adam', 'rmsprop', 'sgd'])\n",
    "    learning_rate = hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_choice == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "\n",
    "    # Loss function\n",
    "    loss_choice = hp.Choice('loss', ['binary_crossentropy', 'mse'])\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=loss_choice,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "tuner = kt.RandomSearch(\n",
    "    build_gru_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=100,\n",
    "    executions_per_trial=1,\n",
    "    directory='dlm',\n",
    "    project_name='gru_tuning',\n",
    "    overwrite=False\n",
    ")\n",
    "tuner.reload()\n",
    "best_hps = tuner.get_best_hyperparameters(1)[0]\n",
    "_gru = tuner.hypermodel.build(best_hps)\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "_gru.compile(optimizer=optimizer, loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T18:31:10.129884Z",
     "iopub.status.busy": "2025-05-18T18:31:10.129191Z",
     "iopub.status.idle": "2025-05-18T18:31:10.137855Z",
     "shell.execute_reply": "2025-05-18T18:31:10.136832Z",
     "shell.execute_reply.started": "2025-05-18T18:31:10.129855Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "input_shape=XTrainRNN.shape[1:]\n",
    "def build_lstm_model(hp):\n",
    "    model = Sequential()\n",
    "    kernel_regularizer = regularizers.l2(hp.Choice('l2_reg', [1e-2, 1e-3, 1e-4]))\n",
    "    # First LSTM layer\n",
    "    model.add(tf.keras.layers.Input(shape=input_shape))\n",
    "    model.add(LSTM(\n",
    "        units=hp.Int('lstm1_units', 64, 256, step=64),\n",
    "        return_sequences=True,\n",
    "        activation='relu',\n",
    "        dropout=hp.Float('lstm1_dropout', 0.1, 0.5, step=0.1),\n",
    "        kernel_regularizer = kernel_regularizer,\n",
    "    ))\n",
    "\n",
    "    # Second LSTM layer\n",
    "    model.add(LSTM(\n",
    "        units=hp.Int('lstm2_units', 32, 128, step=32),\n",
    "        return_sequences=False,\n",
    "        activation='relu',\n",
    "        kernel_regularizer = kernel_regularizer,\n",
    "        dropout=hp.Float('lstm2_dropout', 0.1, 0.5, step=0.1)\n",
    "    ))\n",
    "\n",
    "    # Dense layer\n",
    "    model.add(Dense(units=hp.Int('dense_units', 32, 128, step=32), activation='relu', kernel_regularizer = kernel_regularizer))\n",
    "    model.add(Dropout(hp.Float('dense_dropout', 0.1, 0.5, step=0.1)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Optimizer and learning rate\n",
    "    optimizer_choice = hp.Choice('optimizer', ['adam', 'rmsprop', 'sgd'])\n",
    "    learning_rate = hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_choice == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "\n",
    "    # Loss function\n",
    "    loss_choice = hp.Choice('loss', ['binary_crossentropy', 'mse'])\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss_choice, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    build_lstm_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=100,\n",
    "    executions_per_trial=1,\n",
    "    directory='dlm',\n",
    "    project_name='lstm_tuning',\n",
    "    overwrite=False\n",
    ")\n",
    "tuner.reload()\n",
    "best_hps = tuner.get_best_hyperparameters(1)[0]\n",
    "_lstm = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T18:31:12.630316Z",
     "iopub.status.busy": "2025-05-18T18:31:12.630031Z",
     "iopub.status.idle": "2025-05-18T18:31:12.639778Z",
     "shell.execute_reply": "2025-05-18T18:31:12.639018Z",
     "shell.execute_reply.started": "2025-05-18T18:31:12.630288Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "input_shape=XTrainCNN.shape[1:]\n",
    "def build_cnn_model(hp):\n",
    "    model = Sequential()\n",
    "    kernel_regularizer = regularizers.l2(hp.Choice('l2_reg', [1e-2, 1e-3, 1e-4]))\n",
    "    # Convolutional layers\n",
    "    # Convolutional layers\n",
    "    model.add(tf.keras.layers.Input(shape=input_shape))\n",
    "    model.add(Conv1D(filters=hp.Choice('filters', [8, 16, 32, 64]),\n",
    "                     kernel_size=hp.Choice('kernel_size', [3, 5, 7, 8]),\n",
    "                     activation='relu', padding='same',\n",
    "                     kernel_regularizer = kernel_regularizer, \n",
    "                     ))\n",
    "    model.add(MaxPool1D(pool_size=2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(hp.Float('dropout_rate', 0.2, 0.5, step=0.1)))\n",
    "\n",
    "    model.add(Conv1D(filters=hp.Choice('filters2', [8, 16, 32, 64]),\n",
    "                     kernel_size=hp.Choice('kernel_size2', [3, 5, 7, 8]),\n",
    "                     kernel_regularizer = kernel_regularizer,\n",
    "                     activation='relu', padding='same'))\n",
    "    model.add(MaxPool1D(pool_size=2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(hp.Float('dropout_rate2', 0.2, 0.5, step=0.1)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=hp.Int('dense_units', 32, 512, step=32), activation='relu', kernel_regularizer = kernel_regularizer))\n",
    "    model.add(Dropout(hp.Float('final_dropout', 0.2, 0.5, step=0.1)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Optimizer selection\n",
    "    optimizer_choice = hp.Choice('optimizer', ['adam', 'rmsprop', 'sgd'])\n",
    "    learning_rate = hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_choice == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "\n",
    "    # Compile model with tunable loss\n",
    "    loss_choice = hp.Choice('loss', ['binary_crossentropy', 'mse'])\n",
    "    model.compile(optimizer=optimizer, loss=loss_choice, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    build_cnn_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory='dlm',\n",
    "    project_name='cnn_tuning',\n",
    "    overwrite=False\n",
    ")\n",
    "tuner.reload()\n",
    "best_hps = tuner.get_best_hyperparameters(1)[0]\n",
    "_cnn = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-18T18:31:29.011157Z",
     "iopub.status.busy": "2025-05-18T18:31:29.010495Z",
     "iopub.status.idle": "2025-05-18T18:38:06.636647Z",
     "shell.execute_reply": "2025-05-18T18:38:06.635577Z",
     "shell.execute_reply.started": "2025-05-18T18:31:29.011132Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "_Clfs = [\n",
    "        ('DNN', _dnn),\n",
    "        ('GRU', _gru),\n",
    "        ('LSTM', _lstm),\n",
    "        ('CNN', _cnn)\n",
    "        ]\n",
    "\n",
    "scores, proba, histories = evaluate_classifiers(_Clfs, X_train1, y_train, \n",
    "                                     X_test1, y_test, fea_dim1,\n",
    "                                     training=True, \n",
    "                                     epoc=1500, ep_interval=10, cutoff=0.5)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T18:42:31.761289Z",
     "iopub.status.busy": "2025-05-18T18:42:31.760926Z",
     "iopub.status.idle": "2025-05-18T18:42:35.417235Z",
     "shell.execute_reply": "2025-05-18T18:42:35.416312Z",
     "shell.execute_reply.started": "2025-05-18T18:42:31.761248Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_histories(histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T18:39:41.279017Z",
     "iopub.status.busy": "2025-05-18T18:39:41.278402Z",
     "iopub.status.idle": "2025-05-18T18:39:41.430239Z",
     "shell.execute_reply": "2025-05-18T18:39:41.429309Z",
     "shell.execute_reply.started": "2025-05-18T18:39:41.278988Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "np.save('socres_model_names.npy',scores)\n",
    "np.save('proba_models.npy',proba)\n",
    "np.save('y_test.npy',y_test)\n",
    "np.save('models_history.npy',histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T18:40:57.267689Z",
     "iopub.status.busy": "2025-05-18T18:40:57.267392Z",
     "iopub.status.idle": "2025-05-18T18:40:57.983090Z",
     "shell.execute_reply": "2025-05-18T18:40:57.982160Z",
     "shell.execute_reply.started": "2025-05-18T18:40:57.267668Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def drawCLF_AUC(modelList, probaList, y_test):\n",
    "    # size = size\n",
    "    # num_cross_val = cv  \n",
    "    all_performance = []\n",
    "    all_prob = {}\n",
    "    all_prob[0] = []\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_figheight(6)\n",
    "    fig.set_figwidth(8)\n",
    "    fig.set_dpi(100)\n",
    "    \n",
    "    for proba, name in zip(probaList, modelList):\n",
    "        print(\"Model \", name)\n",
    "        test_label = y_test\n",
    "        _proba = proba #clf.predict(test)\n",
    "\n",
    "        y_pred_xgb = [1 if val >= 0.5 else 0 for val in _proba]\n",
    "\n",
    "        acc, precision, sensitivity, specificity, MCC = calculate_performace(len(test_label),\n",
    "                                                                                               y_pred_xgb,\n",
    "                                                                                               np.array(test_label))\n",
    "\n",
    "    \n",
    "        print('Classification Report:\\n', classification_report(test_label, y_pred_xgb))\n",
    "        fpr_keras, tpr_keras, _ = roc_curve(test_label, _proba)\n",
    "        auc_keras = auc(fpr_keras, tpr_keras)\n",
    "        print('AUC', auc_keras)\n",
    "        linewdth=1\n",
    "        if name=='CNN':\n",
    "            linewdth=2\n",
    "            ax.plot(fpr_keras, tpr_keras, #color='darkblue',\n",
    "                label=r' {} (AUC = %0.4f)'.format(name) % (auc_keras),\n",
    "                lw=linewdth, alpha=.8)\n",
    "        else:\n",
    "            ax.plot(fpr_keras, tpr_keras, #color='grey',\n",
    "                    label=r' {} (AUC = %0.4f)'.format(name) % (auc_keras),\n",
    "                    lw=linewdth, alpha=.8)\n",
    "        interp_tpr = np.interp(mean_fpr, fpr_keras, tpr_keras) \n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "        aucs.append(auc_keras)\n",
    "\n",
    "        # all_labels = all_labels + real_labels\n",
    "        all_prob[0] = all_prob[0] + [val for val in _proba]  \n",
    "        all_performance.append([acc, precision, sensitivity, specificity, MCC])\n",
    "        print('---' * 30)\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', alpha=.6) # label='Mid Point', \n",
    "\n",
    "  \n",
    "    ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
    "           title=\"Receiver operating characteristic curve (ROC-Curve)\")\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    plt.xlabel('False Positive Rate (1 - Specificity) -->')\n",
    "    plt.ylabel('True Positive Rate (Sensitivity) -->')\n",
    "    plt.grid()\n",
    "    \n",
    "    # plt.axes\n",
    "    plt.title('ROC Curve for Different Deep Learning Models')\n",
    "    plt.savefig('ROC_Curve.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "drawCLF_AUC(scores['Model'], proba, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T18:43:33.961135Z",
     "iopub.status.busy": "2025-05-18T18:43:33.960370Z",
     "iopub.status.idle": "2025-05-18T18:43:34.677517Z",
     "shell.execute_reply": "2025-05-18T18:43:34.676549Z",
     "shell.execute_reply.started": "2025-05-18T18:43:33.961104Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def drawCLF_PRCurve(modelList, probaList, y_test):\n",
    "    # size = size\n",
    "    # num_cross_val = cv  \n",
    "    all_performance = []\n",
    "    all_labels = []\n",
    "    all_prob = {}\n",
    "    all_prob[0] = []\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "#     plt.figure(figsize=(6, 6), dpi=300)\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_figheight(6)\n",
    "    fig.set_figwidth(8)\n",
    "    fig.set_dpi(100)\n",
    "    fold = 0\n",
    "    \n",
    "    for proba, name in zip(probaList, modelList):\n",
    "\n",
    "        test_label = y_test\n",
    "        _proba = proba #clf.predict(test)\n",
    "\n",
    "        y_pred = [1 if val >= 0.5 else 0 for val in _proba]\n",
    "\n",
    "        acc, precision, sensitivity, specificity, MCC = calculate_performace(len(test_label),\n",
    "                                                                                               y_pred,\n",
    "                                                                                               np.array(test_label))\n",
    "\n",
    "        print('Classification Report:\\n', classification_report(test_label, y_pred))\n",
    "        pre_keras, rec_keras, _ = precision_recall_curve(test_label, _proba)\n",
    "        auc_keras = average_precision_score(test_label, _proba)\n",
    "        print('mAP', auc_keras)\n",
    "        linewdth=1\n",
    "        if name=='CNN':\n",
    "            linewdth=2\n",
    "            ax.plot(rec_keras, pre_keras, #color='darkblue',\n",
    "                label=r' {} (mAP = %0.4f)'.format(name) % (auc_keras),\n",
    "                lw=linewdth, alpha=.8)\n",
    "        else:\n",
    "            ax.plot(rec_keras, pre_keras, #color='grey',\n",
    "                label=r' {} (mAP = %0.4f)'.format(name) % (auc_keras),\n",
    "                lw=linewdth, alpha=.8)\n",
    "        \n",
    "        interp_tpr = np.interp(mean_fpr, pre_keras, rec_keras) \n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "        aucs.append(auc_keras)\n",
    "\n",
    "        # all_labels = all_labels + real_labels\n",
    "        all_prob[0] = all_prob[0] + [val for val in _proba]  \n",
    "        all_performance.append([acc, precision, sensitivity, specificity, MCC])\n",
    "        print('---' * 30)\n",
    "\n",
    " \n",
    "    ax.legend(loc=\"lower right\")\n",
    "    plt.xlabel('Precision -->')\n",
    "    plt.ylabel('Recall -->')\n",
    "    plt.grid()\n",
    "    plt.title('PR-Curve for Different Deep Learning Models')\n",
    "    plt.savefig('PR_Curve.png', dpi=300, bbox_inches='tight')\n",
    "    # plt.axes\n",
    "    plt.show()\n",
    "\n",
    "drawCLF_PRCurve(scores['Model'], proba, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-Fold Cross-validation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_model():\n",
    "    tuner = kt.RandomSearch(\n",
    "        build_cnn_model,\n",
    "        objective='val_accuracy',\n",
    "        max_trials=10,\n",
    "        executions_per_trial=1,\n",
    "        directory='dlm',\n",
    "        project_name='cnn_tuning',\n",
    "        overwrite=False\n",
    "    )\n",
    "    \n",
    "    tuner.reload()\n",
    "    best_hps = tuner.get_best_hyperparameters(1)[0]\n",
    "\n",
    "    _cnn = tuner.hypermodel.build(best_hps)\n",
    "    learning_rate = 0.001\n",
    "    # if optimizer_choice == 'adam':\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    # Loss function\n",
    "    loss_choice = 'binary_crossentropy' \n",
    "    _cnn.compile(optimizer=optimizer, loss=loss_choice, metrics=['accuracy'])\n",
    "    return _cnn\n",
    "\n",
    "\n",
    "def hm5c_deepCnn_K_fold_CV(cv=10):\n",
    "    \n",
    "    num_cross_val = cv  \n",
    "    all_performance = []\n",
    "    all_labels = []\n",
    "    all_prob = {}\n",
    "    num_classifier = 3\n",
    "    all_prob[0] = []\n",
    "    all_average = []\n",
    "    repeat = 5\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    accs = []\n",
    "    foldnames = []\n",
    "    specs = []\n",
    "    sens = []\n",
    "    mccs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    df = df_main.sample(frac=1, random_state=123)\n",
    "    X = df.iloc[:,1:].values\n",
    "    y = df.iloc[:,:1].values\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    y = encoder.fit_transform(y.ravel())\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    XT = np.delete(X, list_bad_feature1, axis=1)\n",
    "    yT = y\n",
    "    print(XT.shape, y.shape)\n",
    "    _fea_dim = XT.shape[1]\n",
    "    fold = 0\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=cv)\n",
    "    for i, (train_index, test_index) in enumerate(cv.split(XT, yT)):\n",
    "\n",
    "        print(\"Fold \", i)\n",
    "        train, train_label = XT[train_index], yT[train_index]\n",
    "        test, test_label = XT[test_index], yT[test_index]\n",
    "\n",
    "        real_labels = []\n",
    "        for val in test_label:\n",
    "            if val == 1:\n",
    "                real_labels.append(1)\n",
    "            else:\n",
    "                real_labels.append(0)\n",
    "\n",
    "        \n",
    "        clf = get_final_model()\n",
    "        XTrainCNN =np.array(train).reshape(-1, _fea_dim, 1)\n",
    "        XTestCNN = np.array(test).reshape(-1, _fea_dim, 1)\n",
    "        # print(\"Traning \"+clf[0])\n",
    "        callbacks = [\n",
    "                        EarlyStopping(patience=250, monitor='val_accuracy', restore_best_weights=True),\n",
    "                        ReduceLROnPlateau(factor=0.25, patience=100, min_lr=1e-5),\n",
    "                        ModelCheckpoint('{0}_CNN.weights.h5'.format(fold), monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "                    ]\n",
    "        clf.fit(XTrainCNN, train_label, #verbose=1, \n",
    "                    shuffle=True, epochs=1000, \n",
    "                    callbacks=[SelectiveProgbarLogger(verbose = 0, epoch_interval=20),callbacks],\n",
    "                    batch_size=32,\n",
    "                    validation_data=(XTestCNN, test_label))\n",
    "        \n",
    "        _proba = clf.predict(test)\n",
    "        y_pred = [1 if val >= 0.5 else 0 for val in _proba] # \n",
    "\n",
    "        acc, precision, sensitivity, specificity, MCC = calculate_performace(len(test_label),\n",
    "                                                                                               y_pred,\n",
    "                                                                                               np.array(test_label))\n",
    "#         print(fold, acc, precision, sensitivity, specificity, MCC)\n",
    "        foldnames.append(fold); accs.append(acc); sens.append(sensitivity); specs.append(specificity); mccs.append(MCC)\n",
    "        \n",
    "    \n",
    "        print('Classification Report:\\n', classification_report(test_label, y_pred))\n",
    "        fpr_keras, tpr_keras, _ = roc_curve(test_label, _proba)\n",
    "        auc_keras = auc(fpr_keras, tpr_keras)\n",
    "        print('AUC', auc_keras)\n",
    "       \n",
    "        ax.plot(fpr_keras, tpr_keras, #color='grey',\n",
    "                label=r'ROC fold {} (AUC = %0.4f)'.format(fold) % (auc_keras),\n",
    "                lw=1, alpha=.6)\n",
    "        interp_tpr = np.interp(mean_fpr, fpr_keras, tpr_keras) \n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "        aucs.append(auc_keras)\n",
    "\n",
    "        all_labels = all_labels + real_labels\n",
    "        all_prob[0] = all_prob[0] + [val for val in _proba]  \n",
    "        all_performance.append([acc, precision, sensitivity, specificity, MCC])\n",
    "        print('---' * 30)\n",
    "        fold += 1\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', alpha=.6) # label='Mid Point', \n",
    "\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    ax.plot(mean_fpr, mean_tpr, color='b',\n",
    "            label=r'Mean ROC (AUC = %0.4f)' % (mean_auc),\n",
    "            lw=2, alpha=.8)\n",
    "\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                    label=r'$\\pm$ %0.4f std. dev.'% (std_auc))\n",
    "\n",
    "    ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
    "           title=\"ROC-Curve ({0}-fold Cross Validation)\".format(cv))\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    plt.xlabel('False Positive Rate (1 - Specificity) -->')\n",
    "    plt.ylabel('True Positive Rate (Sensitivity) -->')\n",
    "    plt.grid()\n",
    "    plt.title('ROC-Curve ({0}-fold Cross Validation)'.format(cv))\n",
    "    plt.savefig('{0}_fold_ROC_Curve.png'.format(cv), dpi=300, bbox_inches='tight')\n",
    "    # plt.axes\n",
    "    plt.show()\n",
    "\n",
    "    mean_performance = np.mean(np.array(all_performance), axis=0)\n",
    "    meanACC, meanSens, meanSpec, meanMCC, meanAUC = mean_performance[0], mean_performance[2], mean_performance[3], mean_performance[4], mean_auc\n",
    "\n",
    "    meanScore = pd.DataFrame({'Mean ACC': meanACC, 'Mean Sens': meanSens, 'Mean Spec': meanSpec,\n",
    "                              'Mean MCC': meanMCC, 'Mean AUC': meanAUC}, index=[0])\n",
    "    print('---' * 50)\n",
    "    foldScore = pd.DataFrame({'ACC': accs, 'Sen':sens, 'Spec':specs, 'MCC':mccs, 'AUC': aucs})\n",
    "\n",
    "    np.save(\"kfold_socre.npy\",foldScore)\n",
    "    return foldScore, meanScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-18T18:49:35.738690Z",
     "iopub.status.busy": "2025-05-18T18:49:35.738356Z",
     "iopub.status.idle": "2025-05-18T19:03:18.950956Z",
     "shell.execute_reply": "2025-05-18T19:03:18.950075Z",
     "shell.execute_reply.started": "2025-05-18T18:49:35.738666Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "foldScore_hm5C, meanScore_hm5C = hm5c_deepCnn_K_fold_CV(cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T19:04:14.070315Z",
     "iopub.status.busy": "2025-05-18T19:04:14.069364Z",
     "iopub.status.idle": "2025-05-18T19:04:14.084502Z",
     "shell.execute_reply": "2025-05-18T19:04:14.083331Z",
     "shell.execute_reply.started": "2025-05-18T19:04:14.070277Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "foldScore_hm5C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T19:04:16.409366Z",
     "iopub.status.busy": "2025-05-18T19:04:16.408936Z",
     "iopub.status.idle": "2025-05-18T19:04:16.418848Z",
     "shell.execute_reply": "2025-05-18T19:04:16.418011Z",
     "shell.execute_reply.started": "2025-05-18T19:04:16.409339Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "meanScore_hm5C"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5304743,
     "sourceId": 8819059,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7327358,
     "sourceId": 11675948,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
